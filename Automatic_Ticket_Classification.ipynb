{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spdsp04/Automatic_Ticket_Classification/blob/main/Automatic_Ticket_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcAz0wiNSkhV"
      },
      "source": [
        "# Automatic Ticket Classification\n",
        "\n",
        "### By: Durgesh Chaubey"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR-ZUkwJrFn"
      },
      "source": [
        "## Problem Statement \n",
        "\n",
        "You need to build a model that is able to classify customer complaints based on the products/services. By doing so, you can segregate these tickets into their relevant categories and, therefore, help in the quick resolution of the issue.\n",
        "\n",
        "You will be doing topic modelling on the <b>.json</b> data provided by the company. Since this data is not labelled, you need to apply NMF to analyse patterns and classify tickets into the following five clusters based on their products/services:\n",
        "\n",
        "* Credit card / Prepaid card\n",
        "\n",
        "* Bank account services\n",
        "\n",
        "* Theft/Dispute reporting\n",
        "\n",
        "* Mortgages/loans\n",
        "\n",
        "* Others \n",
        "\n",
        "\n",
        "With the help of topic modelling, you will be able to map each ticket onto its respective department/category. You can then use this data to train any supervised model such as logistic regression, decision tree or random forest. Using this trained model, you can classify any new customer complaint support ticket into its relevant department."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcgXVNyaLUFS"
      },
      "source": [
        "## Pipelines that needs to be performed:\n",
        "\n",
        "You need to perform the following eight major tasks to complete the assignment:\n",
        "\n",
        "1.  Data loading\n",
        "\n",
        "2. Text preprocessing\n",
        "\n",
        "3. Exploratory data analysis (EDA)\n",
        "\n",
        "4. Feature extraction\n",
        "\n",
        "5. Topic modelling \n",
        "\n",
        "6. Model building using supervised learning\n",
        "\n",
        "7. Model training and evaluation\n",
        "\n",
        "8. Model inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1rTLfnTjXSu",
        "outputId": "1fd13115-4722-4474-aebe-bbedcfcf0fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Setting up Google Colab for usage. Please disable if running locally.\n",
        "import pathlib\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#base_dir = pathlib.Path('/content/drive/MyDrive/Automatic_Ticket_Classification')\n",
        "#os.chdir(str(base_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuLFIymAL58u"
      },
      "source": [
        "## Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KhC2I7gjUT_",
        "outputId": "ff25c481-f05a-45ec-badf-0b837f6d8fd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.9.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O-Q9pqrcJrFr"
      },
      "outputs": [],
      "source": [
        "import json \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re, nltk, spacy, string\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from plotly.offline import plot\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtRLCsNVJrFt"
      },
      "source": [
        "## 1. Loading the data\n",
        "\n",
        "The data is in JSON format and we need to convert it to a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "puVzIf_iJrFt"
      },
      "outputs": [],
      "source": [
        "# Opening JSON file \n",
        "f = open('/content/drive/MyDrive/Automatic_Ticket_Classification/complaintssc.json')\n",
        "\n",
        "# returns JSON object as a dictionary \n",
        "data = json.load(f)\n",
        "f.close()\n",
        "df=pd.json_normalize(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xYpH-sAJrFu"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q6inExmbTIIk"
      },
      "outputs": [],
      "source": [
        "# Inspect the dataframe to understand the given data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf8ufHH5JrFu",
        "outputId": "307186ef-215d-4b70-a2c7-aeb07d9d4c55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(78313, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Checking shape of dataframe\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T574hQOVjUUS"
      },
      "outputs": [],
      "source": [
        "# Making all columns of the dataframe visible.\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "iUKayO5DjUUT",
        "outputId": "576c8ce0-2586-4f04-c2a5-cc3d5c24a354"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                _index      _type      _id  _score   _source.tags  \\\n",
              "0  complaint-public-v2  complaint  3211475     0.0           None   \n",
              "1  complaint-public-v2  complaint  3229299     0.0  Servicemember   \n",
              "2  complaint-public-v2  complaint  3199379     0.0           None   \n",
              "3  complaint-public-v2  complaint  2673060     0.0           None   \n",
              "4  complaint-public-v2  complaint  3203545     0.0           None   \n",
              "\n",
              "  _source.zip_code _source.complaint_id                       _source.issue  \\\n",
              "0            90301              3211475   Attempts to collect debt not owed   \n",
              "1            319XX              3229299     Written notification about debt   \n",
              "2            77069              3199379  Other features, terms, or problems   \n",
              "3            48066              2673060      Trouble during payment process   \n",
              "4            10473              3203545                    Fees or interest   \n",
              "\n",
              "       _source.date_received _source.state _source.consumer_disputed  \\\n",
              "0  2019-04-13T12:00:00-05:00            CA                       N/A   \n",
              "1  2019-05-01T12:00:00-05:00            GA                       N/A   \n",
              "2  2019-04-02T12:00:00-05:00            TX                       N/A   \n",
              "3  2017-09-13T12:00:00-05:00            MI                       N/A   \n",
              "4  2019-04-05T12:00:00-05:00            NY                       N/A   \n",
              "\n",
              "               _source.product _source.company_response       _source.company  \\\n",
              "0              Debt collection  Closed with explanation  JPMORGAN CHASE & CO.   \n",
              "1              Debt collection  Closed with explanation  JPMORGAN CHASE & CO.   \n",
              "2  Credit card or prepaid card  Closed with explanation  JPMORGAN CHASE & CO.   \n",
              "3                     Mortgage  Closed with explanation  JPMORGAN CHASE & CO.   \n",
              "4  Credit card or prepaid card  Closed with explanation  JPMORGAN CHASE & CO.   \n",
              "\n",
              "  _source.submitted_via _source.date_sent_to_company  \\\n",
              "0                   Web    2019-04-13T12:00:00-05:00   \n",
              "1                   Web    2019-05-01T12:00:00-05:00   \n",
              "2                   Web    2019-04-02T12:00:00-05:00   \n",
              "3                   Web    2017-09-14T12:00:00-05:00   \n",
              "4              Referral    2019-04-05T12:00:00-05:00   \n",
              "\n",
              "  _source.company_public_response                         _source.sub_product  \\\n",
              "0                            None                            Credit card debt   \n",
              "1                            None                            Credit card debt   \n",
              "2                            None  General-purpose credit card or charge card   \n",
              "3                            None                  Conventional home mortgage   \n",
              "4                            None  General-purpose credit card or charge card   \n",
              "\n",
              "  _source.timely                    _source.complaint_what_happened  \\\n",
              "0            Yes                                                      \n",
              "1            Yes  Good morning my name is XXXX XXXX and I apprec...   \n",
              "2            Yes  I upgraded my XXXX XXXX card in XX/XX/2018 and...   \n",
              "3            Yes                                                      \n",
              "4            Yes                                                      \n",
              "\n",
              "                                  _source.sub_issue  \\\n",
              "0                                 Debt is not yours   \n",
              "1  Didn't receive enough information to verify debt   \n",
              "2             Problem with rewards from credit card   \n",
              "3                                              None   \n",
              "4                         Charged too much interest   \n",
              "\n",
              "  _source.consumer_consent_provided  \n",
              "0              Consent not provided  \n",
              "1                  Consent provided  \n",
              "2                  Consent provided  \n",
              "3              Consent not provided  \n",
              "4                               N/A  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9822739e-f8e8-400b-b317-6bcd7bc30e49\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_index</th>\n",
              "      <th>_type</th>\n",
              "      <th>_id</th>\n",
              "      <th>_score</th>\n",
              "      <th>_source.tags</th>\n",
              "      <th>_source.zip_code</th>\n",
              "      <th>_source.complaint_id</th>\n",
              "      <th>_source.issue</th>\n",
              "      <th>_source.date_received</th>\n",
              "      <th>_source.state</th>\n",
              "      <th>_source.consumer_disputed</th>\n",
              "      <th>_source.product</th>\n",
              "      <th>_source.company_response</th>\n",
              "      <th>_source.company</th>\n",
              "      <th>_source.submitted_via</th>\n",
              "      <th>_source.date_sent_to_company</th>\n",
              "      <th>_source.company_public_response</th>\n",
              "      <th>_source.sub_product</th>\n",
              "      <th>_source.timely</th>\n",
              "      <th>_source.complaint_what_happened</th>\n",
              "      <th>_source.sub_issue</th>\n",
              "      <th>_source.consumer_consent_provided</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3211475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>90301</td>\n",
              "      <td>3211475</td>\n",
              "      <td>Attempts to collect debt not owed</td>\n",
              "      <td>2019-04-13T12:00:00-05:00</td>\n",
              "      <td>CA</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Debt collection</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2019-04-13T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>Credit card debt</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td>Debt is not yours</td>\n",
              "      <td>Consent not provided</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3229299</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Servicemember</td>\n",
              "      <td>319XX</td>\n",
              "      <td>3229299</td>\n",
              "      <td>Written notification about debt</td>\n",
              "      <td>2019-05-01T12:00:00-05:00</td>\n",
              "      <td>GA</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Debt collection</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2019-05-01T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>Credit card debt</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Good morning my name is XXXX XXXX and I apprec...</td>\n",
              "      <td>Didn't receive enough information to verify debt</td>\n",
              "      <td>Consent provided</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3199379</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>77069</td>\n",
              "      <td>3199379</td>\n",
              "      <td>Other features, terms, or problems</td>\n",
              "      <td>2019-04-02T12:00:00-05:00</td>\n",
              "      <td>TX</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Credit card or prepaid card</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2019-04-02T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>General-purpose credit card or charge card</td>\n",
              "      <td>Yes</td>\n",
              "      <td>I upgraded my XXXX XXXX card in XX/XX/2018 and...</td>\n",
              "      <td>Problem with rewards from credit card</td>\n",
              "      <td>Consent provided</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>2673060</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>48066</td>\n",
              "      <td>2673060</td>\n",
              "      <td>Trouble during payment process</td>\n",
              "      <td>2017-09-13T12:00:00-05:00</td>\n",
              "      <td>MI</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2017-09-14T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>Conventional home mortgage</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>Consent not provided</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3203545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>10473</td>\n",
              "      <td>3203545</td>\n",
              "      <td>Fees or interest</td>\n",
              "      <td>2019-04-05T12:00:00-05:00</td>\n",
              "      <td>NY</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Credit card or prepaid card</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Referral</td>\n",
              "      <td>2019-04-05T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>General-purpose credit card or charge card</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td>Charged too much interest</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9822739e-f8e8-400b-b317-6bcd7bc30e49')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9822739e-f8e8-400b-b317-6bcd7bc30e49 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9822739e-f8e8-400b-b317-6bcd7bc30e49');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Basic check of what the data looks like\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dQcDAqjjUUW",
        "outputId": "80cc51cd-975f-48fc-ba0e-dc2f79cee418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 78313 entries, 0 to 78312\n",
            "Data columns (total 22 columns):\n",
            " #   Column                             Non-Null Count  Dtype  \n",
            "---  ------                             --------------  -----  \n",
            " 0   _index                             78313 non-null  object \n",
            " 1   _type                              78313 non-null  object \n",
            " 2   _id                                78313 non-null  object \n",
            " 3   _score                             78313 non-null  float64\n",
            " 4   _source.tags                       10900 non-null  object \n",
            " 5   _source.zip_code                   71556 non-null  object \n",
            " 6   _source.complaint_id               78313 non-null  object \n",
            " 7   _source.issue                      78313 non-null  object \n",
            " 8   _source.date_received              78313 non-null  object \n",
            " 9   _source.state                      76322 non-null  object \n",
            " 10  _source.consumer_disputed          78313 non-null  object \n",
            " 11  _source.product                    78313 non-null  object \n",
            " 12  _source.company_response           78313 non-null  object \n",
            " 13  _source.company                    78313 non-null  object \n",
            " 14  _source.submitted_via              78313 non-null  object \n",
            " 15  _source.date_sent_to_company       78313 non-null  object \n",
            " 16  _source.company_public_response    4 non-null      object \n",
            " 17  _source.sub_product                67742 non-null  object \n",
            " 18  _source.timely                     78313 non-null  object \n",
            " 19  _source.complaint_what_happened    78313 non-null  object \n",
            " 20  _source.sub_issue                  32016 non-null  object \n",
            " 21  _source.consumer_consent_provided  77305 non-null  object \n",
            "dtypes: float64(1), object(21)\n",
            "memory usage: 13.1+ MB\n"
          ]
        }
      ],
      "source": [
        "# Inspecting column info\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dwcty-wmJrFw",
        "outputId": "649c17d5-51e2-46ed-eb66-6949aa7eea76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns names:\n",
            " ['_index', '_type', '_id', '_score', '_source.tags', '_source.zip_code', '_source.complaint_id', '_source.issue', '_source.date_received', '_source.state', '_source.consumer_disputed', '_source.product', '_source.company_response', '_source.company', '_source.submitted_via', '_source.date_sent_to_company', '_source.company_public_response', '_source.sub_product', '_source.timely', '_source.complaint_what_happened', '_source.sub_issue', '_source.consumer_consent_provided']\n"
          ]
        }
      ],
      "source": [
        "#print the column names\n",
        "cols = df.columns.to_list()\n",
        "print(\"Columns names:\\n\",cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg3I9_6HjUUX",
        "outputId": "2393f565-9db2-4b42-bca5-eb8d6128a1d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_index                                   0\n",
              "_type                                    0\n",
              "_id                                      0\n",
              "_score                                   0\n",
              "_source.tags                         67413\n",
              "_source.zip_code                      6757\n",
              "_source.complaint_id                     0\n",
              "_source.issue                            0\n",
              "_source.date_received                    0\n",
              "_source.state                         1991\n",
              "_source.consumer_disputed                0\n",
              "_source.product                          0\n",
              "_source.company_response                 0\n",
              "_source.company                          0\n",
              "_source.submitted_via                    0\n",
              "_source.date_sent_to_company             0\n",
              "_source.company_public_response      78309\n",
              "_source.sub_product                  10571\n",
              "_source.timely                           0\n",
              "_source.complaint_what_happened          0\n",
              "_source.sub_issue                    46297\n",
              "_source.consumer_consent_provided     1008\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Checking null value counts for each column.\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPrU5XSIjUUY"
      },
      "source": [
        "Columns which begin with \"_source._\" can be problematic in python/pandas. Hence, we should remove the prefixes to avoid any issues in the future.\n",
        "Also removing the underscore at the beginning of column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "FYCtKXD1JrFw",
        "outputId": "5dd1e478-00dc-489a-93be-708bda42a355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New column names:\n",
            " ['index', 'type', 'id', 'score', 'tags', 'zip_code', 'complaint_id', 'issue', 'date_received', 'state', 'consumer_disputed', 'product', 'company_response', 'company', 'submitted_via', 'date_sent_to_company', 'company_public_response', 'sub_product', 'timely', 'complaint_what_happened', 'sub_issue', 'consumer_consent_provided'] \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 index       type       id  score           tags zip_code  \\\n",
              "0  complaint-public-v2  complaint  3211475    0.0           None    90301   \n",
              "1  complaint-public-v2  complaint  3229299    0.0  Servicemember    319XX   \n",
              "2  complaint-public-v2  complaint  3199379    0.0           None    77069   \n",
              "3  complaint-public-v2  complaint  2673060    0.0           None    48066   \n",
              "4  complaint-public-v2  complaint  3203545    0.0           None    10473   \n",
              "\n",
              "  complaint_id                               issue              date_received  \\\n",
              "0      3211475   Attempts to collect debt not owed  2019-04-13T12:00:00-05:00   \n",
              "1      3229299     Written notification about debt  2019-05-01T12:00:00-05:00   \n",
              "2      3199379  Other features, terms, or problems  2019-04-02T12:00:00-05:00   \n",
              "3      2673060      Trouble during payment process  2017-09-13T12:00:00-05:00   \n",
              "4      3203545                    Fees or interest  2019-04-05T12:00:00-05:00   \n",
              "\n",
              "  state consumer_disputed                      product  \\\n",
              "0    CA               N/A              Debt collection   \n",
              "1    GA               N/A              Debt collection   \n",
              "2    TX               N/A  Credit card or prepaid card   \n",
              "3    MI               N/A                     Mortgage   \n",
              "4    NY               N/A  Credit card or prepaid card   \n",
              "\n",
              "          company_response               company submitted_via  \\\n",
              "0  Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
              "1  Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
              "2  Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
              "3  Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
              "4  Closed with explanation  JPMORGAN CHASE & CO.      Referral   \n",
              "\n",
              "        date_sent_to_company company_public_response  \\\n",
              "0  2019-04-13T12:00:00-05:00                    None   \n",
              "1  2019-05-01T12:00:00-05:00                    None   \n",
              "2  2019-04-02T12:00:00-05:00                    None   \n",
              "3  2017-09-14T12:00:00-05:00                    None   \n",
              "4  2019-04-05T12:00:00-05:00                    None   \n",
              "\n",
              "                                  sub_product timely  \\\n",
              "0                            Credit card debt    Yes   \n",
              "1                            Credit card debt    Yes   \n",
              "2  General-purpose credit card or charge card    Yes   \n",
              "3                  Conventional home mortgage    Yes   \n",
              "4  General-purpose credit card or charge card    Yes   \n",
              "\n",
              "                             complaint_what_happened  \\\n",
              "0                                                      \n",
              "1  Good morning my name is XXXX XXXX and I apprec...   \n",
              "2  I upgraded my XXXX XXXX card in XX/XX/2018 and...   \n",
              "3                                                      \n",
              "4                                                      \n",
              "\n",
              "                                          sub_issue consumer_consent_provided  \n",
              "0                                 Debt is not yours      Consent not provided  \n",
              "1  Didn't receive enough information to verify debt          Consent provided  \n",
              "2             Problem with rewards from credit card          Consent provided  \n",
              "3                                              None      Consent not provided  \n",
              "4                         Charged too much interest                       N/A  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23fe8b88-3ed6-49e6-a1ab-52f0426baead\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>type</th>\n",
              "      <th>id</th>\n",
              "      <th>score</th>\n",
              "      <th>tags</th>\n",
              "      <th>zip_code</th>\n",
              "      <th>complaint_id</th>\n",
              "      <th>issue</th>\n",
              "      <th>date_received</th>\n",
              "      <th>state</th>\n",
              "      <th>consumer_disputed</th>\n",
              "      <th>product</th>\n",
              "      <th>company_response</th>\n",
              "      <th>company</th>\n",
              "      <th>submitted_via</th>\n",
              "      <th>date_sent_to_company</th>\n",
              "      <th>company_public_response</th>\n",
              "      <th>sub_product</th>\n",
              "      <th>timely</th>\n",
              "      <th>complaint_what_happened</th>\n",
              "      <th>sub_issue</th>\n",
              "      <th>consumer_consent_provided</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3211475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>90301</td>\n",
              "      <td>3211475</td>\n",
              "      <td>Attempts to collect debt not owed</td>\n",
              "      <td>2019-04-13T12:00:00-05:00</td>\n",
              "      <td>CA</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Debt collection</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2019-04-13T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>Credit card debt</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td>Debt is not yours</td>\n",
              "      <td>Consent not provided</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3229299</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Servicemember</td>\n",
              "      <td>319XX</td>\n",
              "      <td>3229299</td>\n",
              "      <td>Written notification about debt</td>\n",
              "      <td>2019-05-01T12:00:00-05:00</td>\n",
              "      <td>GA</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Debt collection</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2019-05-01T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>Credit card debt</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Good morning my name is XXXX XXXX and I apprec...</td>\n",
              "      <td>Didn't receive enough information to verify debt</td>\n",
              "      <td>Consent provided</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3199379</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>77069</td>\n",
              "      <td>3199379</td>\n",
              "      <td>Other features, terms, or problems</td>\n",
              "      <td>2019-04-02T12:00:00-05:00</td>\n",
              "      <td>TX</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Credit card or prepaid card</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2019-04-02T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>General-purpose credit card or charge card</td>\n",
              "      <td>Yes</td>\n",
              "      <td>I upgraded my XXXX XXXX card in XX/XX/2018 and...</td>\n",
              "      <td>Problem with rewards from credit card</td>\n",
              "      <td>Consent provided</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>2673060</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>48066</td>\n",
              "      <td>2673060</td>\n",
              "      <td>Trouble during payment process</td>\n",
              "      <td>2017-09-13T12:00:00-05:00</td>\n",
              "      <td>MI</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2017-09-14T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>Conventional home mortgage</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>Consent not provided</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3203545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>10473</td>\n",
              "      <td>3203545</td>\n",
              "      <td>Fees or interest</td>\n",
              "      <td>2019-04-05T12:00:00-05:00</td>\n",
              "      <td>NY</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Credit card or prepaid card</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Referral</td>\n",
              "      <td>2019-04-05T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>General-purpose credit card or charge card</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td>Charged too much interest</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23fe8b88-3ed6-49e6-a1ab-52f0426baead')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23fe8b88-3ed6-49e6-a1ab-52f0426baead button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23fe8b88-3ed6-49e6-a1ab-52f0426baead');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#Assign new column names\n",
        "cols_new = [re.sub('source.','',col[1:]) for col in cols]\n",
        "print(\"New column names:\\n\",cols_new, \"\\n\")\n",
        "\n",
        "# Applying new column names\n",
        "df.columns = cols_new\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzPzie4vjUUa"
      },
      "source": [
        "#### Initial insights\n",
        "- Our primary column of interest is \"complaint_what_happened\". There seem to be some blanks in this column as well, which would render these rows useless for our use.\n",
        "- These rows may be deleted.\n",
        "- The column names have been updated to avoid any issues with existing dots (.) in the column names.\n",
        "- Several of the other columns can be dropped, which shall be done in time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcAkBh_4jUUc",
        "outputId": "86246539-4ad6-4a5c-8aba-5da5b834d0e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Checking no. of null values in \"complaints_what_happened\" column.\n",
        "df.complaint_what_happened.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGdWspgxjUUd",
        "outputId": "5cdacfad-9c2a-4528-e252-e6c1c118c1b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of rows with blank complaints:  57241\n"
          ]
        }
      ],
      "source": [
        "# Number of rows with blank complaints\n",
        "print(\"No. of rows with blank complaints: \",len(df[(df.complaint_what_happened == \"\") | (df.complaint_what_happened == \" \")]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grQUPFL5JrFx",
        "outputId": "83cfa681-5b60-4321-c91c-3609f067dd27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of rows with nan in complaints column:  57241\n"
          ]
        }
      ],
      "source": [
        "#Assign nan in place of blanks in the complaints column\n",
        "df['complaint_what_happened'] = df['complaint_what_happened'].replace(r\"^\\s*$\",np.NaN,regex=True)\n",
        "print(\"No. of rows with nan in complaints column: \", df.complaint_what_happened.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dBBugSbjUUf",
        "outputId": "eaeca4cc-e335-49a4-c67d-82ba630b0741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of rows with blank complaints:  0\n"
          ]
        }
      ],
      "source": [
        "# Number of rows with blank complaints after replacing with NaN\n",
        "print(\"No. of rows with blank complaints: \",len(df[(df.complaint_what_happened == \"\") | (df.complaint_what_happened == \" \")]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfxd8VSmJrFy",
        "outputId": "cfaff052-6968-4796-f889-e9d19d660c28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New shape of dataframe: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21072, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#Remove all rows where complaints column is nan\n",
        "df = df[~df['complaint_what_happened'].isnull()]\n",
        "\n",
        "print(\"New shape of dataframe: \")\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "vX2iloXkjUUi",
        "outputId": "8f2ca9cd-552f-4ec0-8f40-43eea154b027"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  index       type       id  score           tags zip_code  \\\n",
              "1   complaint-public-v2  complaint  3229299    0.0  Servicemember    319XX   \n",
              "2   complaint-public-v2  complaint  3199379    0.0           None    77069   \n",
              "10  complaint-public-v2  complaint  3233499    0.0           None    104XX   \n",
              "11  complaint-public-v2  complaint  3180294    0.0           None    750XX   \n",
              "14  complaint-public-v2  complaint  3224980    0.0           None    920XX   \n",
              "\n",
              "   complaint_id                                 issue  \\\n",
              "1       3229299       Written notification about debt   \n",
              "2       3199379    Other features, terms, or problems   \n",
              "10      3233499  Incorrect information on your report   \n",
              "11      3180294  Incorrect information on your report   \n",
              "14      3224980                   Managing an account   \n",
              "\n",
              "                date_received state consumer_disputed  \\\n",
              "1   2019-05-01T12:00:00-05:00    GA               N/A   \n",
              "2   2019-04-02T12:00:00-05:00    TX               N/A   \n",
              "10  2019-05-06T12:00:00-05:00    NY               N/A   \n",
              "11  2019-03-14T12:00:00-05:00    TX               N/A   \n",
              "14  2019-04-27T12:00:00-05:00    CA               N/A   \n",
              "\n",
              "                                              product  \\\n",
              "1                                     Debt collection   \n",
              "2                         Credit card or prepaid card   \n",
              "10  Credit reporting, credit repair services, or o...   \n",
              "11  Credit reporting, credit repair services, or o...   \n",
              "14                        Checking or savings account   \n",
              "\n",
              "           company_response               company submitted_via  \\\n",
              "1   Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
              "2   Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
              "10  Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
              "11  Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
              "14  Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
              "\n",
              "         date_sent_to_company company_public_response  \\\n",
              "1   2019-05-01T12:00:00-05:00                    None   \n",
              "2   2019-04-02T12:00:00-05:00                    None   \n",
              "10  2019-05-06T12:00:00-05:00                    None   \n",
              "11  2019-03-15T12:00:00-05:00                    None   \n",
              "14  2019-04-27T12:00:00-05:00                    None   \n",
              "\n",
              "                                   sub_product timely  \\\n",
              "1                             Credit card debt    Yes   \n",
              "2   General-purpose credit card or charge card    Yes   \n",
              "10              Other personal consumer report    Yes   \n",
              "11                            Credit reporting    Yes   \n",
              "14                            Checking account    Yes   \n",
              "\n",
              "                              complaint_what_happened  \\\n",
              "1   Good morning my name is XXXX XXXX and I apprec...   \n",
              "2   I upgraded my XXXX XXXX card in XX/XX/2018 and...   \n",
              "10  Chase Card was reported on XX/XX/2019. However...   \n",
              "11  On XX/XX/2018, while trying to book a XXXX  XX...   \n",
              "14  my grand son give me check for {$1600.00} i de...   \n",
              "\n",
              "                                           sub_issue consumer_consent_provided  \n",
              "1   Didn't receive enough information to verify debt          Consent provided  \n",
              "2              Problem with rewards from credit card          Consent provided  \n",
              "10               Information belongs to someone else          Consent provided  \n",
              "11               Information belongs to someone else          Consent provided  \n",
              "14      Funds not handled or disbursed as instructed          Consent provided  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-646c2bdd-600a-496e-b48b-500e5b9cb760\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>type</th>\n",
              "      <th>id</th>\n",
              "      <th>score</th>\n",
              "      <th>tags</th>\n",
              "      <th>zip_code</th>\n",
              "      <th>complaint_id</th>\n",
              "      <th>issue</th>\n",
              "      <th>date_received</th>\n",
              "      <th>state</th>\n",
              "      <th>consumer_disputed</th>\n",
              "      <th>product</th>\n",
              "      <th>company_response</th>\n",
              "      <th>company</th>\n",
              "      <th>submitted_via</th>\n",
              "      <th>date_sent_to_company</th>\n",
              "      <th>company_public_response</th>\n",
              "      <th>sub_product</th>\n",
              "      <th>timely</th>\n",
              "      <th>complaint_what_happened</th>\n",
              "      <th>sub_issue</th>\n",
              "      <th>consumer_consent_provided</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3229299</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Servicemember</td>\n",
              "      <td>319XX</td>\n",
              "      <td>3229299</td>\n",
              "      <td>Written notification about debt</td>\n",
              "      <td>2019-05-01T12:00:00-05:00</td>\n",
              "      <td>GA</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Debt collection</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2019-05-01T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>Credit card debt</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Good morning my name is XXXX XXXX and I apprec...</td>\n",
              "      <td>Didn't receive enough information to verify debt</td>\n",
              "      <td>Consent provided</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3199379</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>77069</td>\n",
              "      <td>3199379</td>\n",
              "      <td>Other features, terms, or problems</td>\n",
              "      <td>2019-04-02T12:00:00-05:00</td>\n",
              "      <td>TX</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Credit card or prepaid card</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2019-04-02T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>General-purpose credit card or charge card</td>\n",
              "      <td>Yes</td>\n",
              "      <td>I upgraded my XXXX XXXX card in XX/XX/2018 and...</td>\n",
              "      <td>Problem with rewards from credit card</td>\n",
              "      <td>Consent provided</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3233499</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>104XX</td>\n",
              "      <td>3233499</td>\n",
              "      <td>Incorrect information on your report</td>\n",
              "      <td>2019-05-06T12:00:00-05:00</td>\n",
              "      <td>NY</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Credit reporting, credit repair services, or o...</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2019-05-06T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>Other personal consumer report</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Chase Card was reported on XX/XX/2019. However...</td>\n",
              "      <td>Information belongs to someone else</td>\n",
              "      <td>Consent provided</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3180294</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>750XX</td>\n",
              "      <td>3180294</td>\n",
              "      <td>Incorrect information on your report</td>\n",
              "      <td>2019-03-14T12:00:00-05:00</td>\n",
              "      <td>TX</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Credit reporting, credit repair services, or o...</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2019-03-15T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>Credit reporting</td>\n",
              "      <td>Yes</td>\n",
              "      <td>On XX/XX/2018, while trying to book a XXXX  XX...</td>\n",
              "      <td>Information belongs to someone else</td>\n",
              "      <td>Consent provided</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3224980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>920XX</td>\n",
              "      <td>3224980</td>\n",
              "      <td>Managing an account</td>\n",
              "      <td>2019-04-27T12:00:00-05:00</td>\n",
              "      <td>CA</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Checking or savings account</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2019-04-27T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>Checking account</td>\n",
              "      <td>Yes</td>\n",
              "      <td>my grand son give me check for {$1600.00} i de...</td>\n",
              "      <td>Funds not handled or disbursed as instructed</td>\n",
              "      <td>Consent provided</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-646c2bdd-600a-496e-b48b-500e5b9cb760')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-646c2bdd-600a-496e-b48b-500e5b9cb760 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-646c2bdd-600a-496e-b48b-500e5b9cb760');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L944HZpsJrFy"
      },
      "source": [
        "## 2. Text pre-processing\n",
        "## Prepare the text for topic modeling\n",
        "\n",
        "Once you have removed all the blank complaints, you need to:\n",
        "\n",
        "* Make the text lowercase\n",
        "* Remove text in square brackets\n",
        "* Remove punctuation\n",
        "* Remove words containing numbers\n",
        "\n",
        "\n",
        "Once you have done these cleaning operations you need to perform the following:\n",
        "* Lemmatize the texts\n",
        "* Use POS tags to get relevant words from the texts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qm7SjjSkJrFz"
      },
      "outputs": [],
      "source": [
        "# Write your function here to clean the text and remove all the unnecessary elements.\n",
        "def text_preprocess(text):\n",
        "    # Text to lower case\n",
        "    text1 = text.lower()\n",
        "    \n",
        "    # Removing any leading and trailing spaces\n",
        "    text2 = text1.strip()\n",
        "    \n",
        "    # Removing text within square brackets\n",
        "    text3 = re.sub(r\"[\\[].*?[\\]]\",\"\",text2).strip()\n",
        "    \n",
        "    # Removing punctuations\n",
        "    text4 = re.sub(r\"[^\\w\\s]\",\"\",text3).strip()\n",
        "    \n",
        "    # Removing words containing numbers\n",
        "    text5 = re.sub(\"\\S*\\d\\S*\",\"\",text4).strip()   \n",
        "    \n",
        "    return text5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "fGT81crFjUUk",
        "outputId": "dbc7fa69-cfee-4ba0-e809-4c1db83fcaa0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  index       type       id  score           tags zip_code  \\\n",
              "1   complaint-public-v2  complaint  3229299    0.0  Servicemember    319XX   \n",
              "2   complaint-public-v2  complaint  3199379    0.0           None    77069   \n",
              "10  complaint-public-v2  complaint  3233499    0.0           None    104XX   \n",
              "11  complaint-public-v2  complaint  3180294    0.0           None    750XX   \n",
              "14  complaint-public-v2  complaint  3224980    0.0           None    920XX   \n",
              "\n",
              "   complaint_id                                 issue  \\\n",
              "1       3229299       Written notification about debt   \n",
              "2       3199379    Other features, terms, or problems   \n",
              "10      3233499  Incorrect information on your report   \n",
              "11      3180294  Incorrect information on your report   \n",
              "14      3224980                   Managing an account   \n",
              "\n",
              "                date_received state consumer_disputed  \\\n",
              "1   2019-05-01T12:00:00-05:00    GA               N/A   \n",
              "2   2019-04-02T12:00:00-05:00    TX               N/A   \n",
              "10  2019-05-06T12:00:00-05:00    NY               N/A   \n",
              "11  2019-03-14T12:00:00-05:00    TX               N/A   \n",
              "14  2019-04-27T12:00:00-05:00    CA               N/A   \n",
              "\n",
              "                                              product  \\\n",
              "1                                     Debt collection   \n",
              "2                         Credit card or prepaid card   \n",
              "10  Credit reporting, credit repair services, or o...   \n",
              "11  Credit reporting, credit repair services, or o...   \n",
              "14                        Checking or savings account   \n",
              "\n",
              "           company_response               company submitted_via  \\\n",
              "1   Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
              "2   Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
              "10  Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
              "11  Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
              "14  Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
              "\n",
              "         date_sent_to_company company_public_response  \\\n",
              "1   2019-05-01T12:00:00-05:00                    None   \n",
              "2   2019-04-02T12:00:00-05:00                    None   \n",
              "10  2019-05-06T12:00:00-05:00                    None   \n",
              "11  2019-03-15T12:00:00-05:00                    None   \n",
              "14  2019-04-27T12:00:00-05:00                    None   \n",
              "\n",
              "                                   sub_product timely  \\\n",
              "1                             Credit card debt    Yes   \n",
              "2   General-purpose credit card or charge card    Yes   \n",
              "10              Other personal consumer report    Yes   \n",
              "11                            Credit reporting    Yes   \n",
              "14                            Checking account    Yes   \n",
              "\n",
              "                              complaint_what_happened  \\\n",
              "1   Good morning my name is XXXX XXXX and I apprec...   \n",
              "2   I upgraded my XXXX XXXX card in XX/XX/2018 and...   \n",
              "10  Chase Card was reported on XX/XX/2019. However...   \n",
              "11  On XX/XX/2018, while trying to book a XXXX  XX...   \n",
              "14  my grand son give me check for {$1600.00} i de...   \n",
              "\n",
              "                                           sub_issue  \\\n",
              "1   Didn't receive enough information to verify debt   \n",
              "2              Problem with rewards from credit card   \n",
              "10               Information belongs to someone else   \n",
              "11               Information belongs to someone else   \n",
              "14      Funds not handled or disbursed as instructed   \n",
              "\n",
              "   consumer_consent_provided  \\\n",
              "1           Consent provided   \n",
              "2           Consent provided   \n",
              "10          Consent provided   \n",
              "11          Consent provided   \n",
              "14          Consent provided   \n",
              "\n",
              "                                   complaints_cleaned  \n",
              "1   good morning my name is xxxx xxxx and i apprec...  \n",
              "2   i upgraded my xxxx xxxx card in  and was told ...  \n",
              "10  chase card was reported on  however fraudulent...  \n",
              "11  on  while trying to book a xxxx  xxxx  ticket ...  \n",
              "14  my grand son give me check for  i deposit it i...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c7d29b9-85a7-4587-8783-be0b2bcb39df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>type</th>\n",
              "      <th>id</th>\n",
              "      <th>score</th>\n",
              "      <th>tags</th>\n",
              "      <th>zip_code</th>\n",
              "      <th>complaint_id</th>\n",
              "      <th>issue</th>\n",
              "      <th>date_received</th>\n",
              "      <th>state</th>\n",
              "      <th>consumer_disputed</th>\n",
              "      <th>product</th>\n",
              "      <th>company_response</th>\n",
              "      <th>company</th>\n",
              "      <th>submitted_via</th>\n",
              "      <th>date_sent_to_company</th>\n",
              "      <th>company_public_response</th>\n",
              "      <th>sub_product</th>\n",
              "      <th>timely</th>\n",
              "      <th>complaint_what_happened</th>\n",
              "      <th>sub_issue</th>\n",
              "      <th>consumer_consent_provided</th>\n",
              "      <th>complaints_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3229299</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Servicemember</td>\n",
              "      <td>319XX</td>\n",
              "      <td>3229299</td>\n",
              "      <td>Written notification about debt</td>\n",
              "      <td>2019-05-01T12:00:00-05:00</td>\n",
              "      <td>GA</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Debt collection</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2019-05-01T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>Credit card debt</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Good morning my name is XXXX XXXX and I apprec...</td>\n",
              "      <td>Didn't receive enough information to verify debt</td>\n",
              "      <td>Consent provided</td>\n",
              "      <td>good morning my name is xxxx xxxx and i apprec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3199379</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>77069</td>\n",
              "      <td>3199379</td>\n",
              "      <td>Other features, terms, or problems</td>\n",
              "      <td>2019-04-02T12:00:00-05:00</td>\n",
              "      <td>TX</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Credit card or prepaid card</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2019-04-02T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>General-purpose credit card or charge card</td>\n",
              "      <td>Yes</td>\n",
              "      <td>I upgraded my XXXX XXXX card in XX/XX/2018 and...</td>\n",
              "      <td>Problem with rewards from credit card</td>\n",
              "      <td>Consent provided</td>\n",
              "      <td>i upgraded my xxxx xxxx card in  and was told ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3233499</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>104XX</td>\n",
              "      <td>3233499</td>\n",
              "      <td>Incorrect information on your report</td>\n",
              "      <td>2019-05-06T12:00:00-05:00</td>\n",
              "      <td>NY</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Credit reporting, credit repair services, or o...</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2019-05-06T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>Other personal consumer report</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Chase Card was reported on XX/XX/2019. However...</td>\n",
              "      <td>Information belongs to someone else</td>\n",
              "      <td>Consent provided</td>\n",
              "      <td>chase card was reported on  however fraudulent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3180294</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>750XX</td>\n",
              "      <td>3180294</td>\n",
              "      <td>Incorrect information on your report</td>\n",
              "      <td>2019-03-14T12:00:00-05:00</td>\n",
              "      <td>TX</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Credit reporting, credit repair services, or o...</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2019-03-15T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>Credit reporting</td>\n",
              "      <td>Yes</td>\n",
              "      <td>On XX/XX/2018, while trying to book a XXXX  XX...</td>\n",
              "      <td>Information belongs to someone else</td>\n",
              "      <td>Consent provided</td>\n",
              "      <td>on  while trying to book a xxxx  xxxx  ticket ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>complaint-public-v2</td>\n",
              "      <td>complaint</td>\n",
              "      <td>3224980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>920XX</td>\n",
              "      <td>3224980</td>\n",
              "      <td>Managing an account</td>\n",
              "      <td>2019-04-27T12:00:00-05:00</td>\n",
              "      <td>CA</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Checking or savings account</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
              "      <td>Web</td>\n",
              "      <td>2019-04-27T12:00:00-05:00</td>\n",
              "      <td>None</td>\n",
              "      <td>Checking account</td>\n",
              "      <td>Yes</td>\n",
              "      <td>my grand son give me check for {$1600.00} i de...</td>\n",
              "      <td>Funds not handled or disbursed as instructed</td>\n",
              "      <td>Consent provided</td>\n",
              "      <td>my grand son give me check for  i deposit it i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c7d29b9-85a7-4587-8783-be0b2bcb39df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1c7d29b9-85a7-4587-8783-be0b2bcb39df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1c7d29b9-85a7-4587-8783-be0b2bcb39df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df['complaints_cleaned'] = df.complaint_what_happened.apply(text_preprocess)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Dqwu3ZOjUUm",
        "outputId": "66ff91bc-158a-4fce-e119-b9114284cfc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "# Importing libraries for text processing steps.\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vs28T318jUUm",
        "outputId": "b6d553f8-a521-4f93-b223-8d78e9b48d8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           complaints\n",
              "1   good morning my name is xxxx xxxx and i apprec...\n",
              "2   i upgraded my xxxx xxxx card in  and was told ...\n",
              "10  chase card was reported on  however fraudulent...\n",
              "11  on  while trying to book a xxxx  xxxx  ticket ...\n",
              "14  my grand son give me check for  i deposit it i..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ce47612-9a4c-4432-9631-71200ae874a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>complaints</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>good morning my name is xxxx xxxx and i apprec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i upgraded my xxxx xxxx card in  and was told ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>chase card was reported on  however fraudulent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>on  while trying to book a xxxx  xxxx  ticket ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>my grand son give me check for  i deposit it i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ce47612-9a4c-4432-9631-71200ae874a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ce47612-9a4c-4432-9631-71200ae874a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ce47612-9a4c-4432-9631-71200ae874a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "df_clean = df.complaints_cleaned.to_frame()\n",
        "df_clean.columns = [\"complaints\"]\n",
        "df_clean.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AxaxpKivjUUn",
        "outputId": "0e59816a-f1bb-4a13-980c-930708296fdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting swifter\n",
            "  Downloading swifter-1.3.3.tar.gz (821 kB)\n",
            "\u001b[K     |████████████████████████████████| 821 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (1.3.5)\n",
            "Collecting psutil>=5.6.6\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[K     |████████████████████████████████| 281 kB 45.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dask[dataframe]>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (2.12.0)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (4.64.0)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (7.7.1)\n",
            "Requirement already satisfied: cloudpickle>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from swifter) (1.3.0)\n",
            "Requirement already satisfied: parso>0.4.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (0.8.3)\n",
            "Requirement already satisfied: bleach>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from swifter) (5.0.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bleach>=3.1.1->swifter) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach>=3.1.1->swifter) (0.5.1)\n",
            "Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]>=2.10.0->swifter) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]>=2.10.0->swifter) (1.21.6)\n",
            "Collecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 43.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->swifter) (3.6.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->swifter) (1.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->swifter) (5.5.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->swifter) (4.10.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->swifter) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->swifter) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.7.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->swifter) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->swifter) (2022.1)\n",
            "Collecting locket\n",
            "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.2.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (0.13.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (4.11.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (5.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (2.11.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (23.2.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (2.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (0.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (0.6.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (2.16.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (5.9.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (0.18.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (4.12.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (22.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (4.1.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (3.8.1)\n",
            "Building wheels for collected packages: swifter\n",
            "  Building wheel for swifter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for swifter: filename=swifter-1.3.3-py3-none-any.whl size=16253 sha256=af6437eac40bcbb928899390a1b0aa7df8717cb374d6d6393dda28ae0e6d6db6\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/bf/da/da0022edab5fd84114858a95e4f32f2fca0d5b7d758905f594\n",
            "Successfully built swifter\n",
            "Installing collected packages: locket, partd, fsspec, psutil, swifter\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed fsspec-2022.7.1 locket-1.0.0 partd-1.2.0 psutil-5.9.1 swifter-1.3.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Importing \"swifter\" to speed up lemmatization using mutithread processing.\n",
        "\n",
        "!pip install swifter\n",
        "import swifter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "51tm1zvJjUUo"
      },
      "outputs": [],
      "source": [
        "#Write your function to Lemmatize the texts\n",
        "\n",
        "stopwords = stopwords.words('english')\n",
        "wordnet_lem = WordNetLemmatizer()\n",
        "\n",
        "def lemmatizer(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stopwords]\n",
        "    proc_token = []\n",
        "    # Using nltk pos tagger which may not capture the context like Spacy's POS tagger. However, it should be good enough for use here.\n",
        "    for word,pos in pos_tag(tokens):\n",
        "        try:\n",
        "            proc_token.append(wordnet_lem.lemmatize(word,pos = pos[0].lower()))\n",
        "        except:\n",
        "            proc_token.append(wordnet_lem.lemmatize(word))\n",
        "    lemmatized_text = ' '.join(proc_token)\n",
        "    return lemmatized_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uXnN7aa_JrF0",
        "outputId": "3d343616-10d7-4caf-d99a-11c13b39997c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4.zip/omw-1.4/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-61110f61c6ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Apply lemmatization and store the output in a separate column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lemmatized_complaints\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"complaints_cleaned\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswifter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/swifter/swifter.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mERRORS_TO_HANDLE\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# if can't vectorize, estimate time to pandas apply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mtimed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_REPEATS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0msample_proc_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimed\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN_REPEATS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mest_apply_duration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_proc_est\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SAMPLE_SIZE\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/timeit.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(stmt, setup, timer, number, globals)\u001b[0m\n\u001b[1;32m    231\u001b[0m            number=default_number, globals=None):\n\u001b[1;32m    232\u001b[0m     \u001b[0;34m\"\"\"Convenience function to create Timer object and call timeit method.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m def repeat(stmt=\"pass\", setup=\"pass\", timer=default_timer,\n",
            "\u001b[0;32m/usr/lib/python3.7/timeit.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/timeit.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer, _stmt)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/swifter/swifter.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m()\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msuppress_stdout_stderr_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SAMPLE_INDEX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m                     \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m                 )\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-25dc7e5079ed>\u001b[0m in \u001b[0;36mlemmatizer\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mproc_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordnet_lem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mproc_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordnet_lem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mlemmatized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlemmatized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/stem/wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlemma\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mword\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\"\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__reader_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# This is where the magic happens!  Transform ourselves into\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, omw_reader)\u001b[0m\n\u001b[1;32m   1174\u001b[0m             )\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovenances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0momw_prov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# A cache to store the wordnet data of multiple languages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36momw_prov\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0mprovdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0mprovdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eng\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_omw_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfileid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0mprov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlangfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "#Create a dataframe('df_clean') that will have only the complaints and the lemmatized complaints \n",
        "df_clean = df[[\"complaint_what_happened\",\"complaints_cleaned\"]]\n",
        "#df_clean.columns = [\"raw_complaints\",\"cleaned_complaints\"]\n",
        "\n",
        "# Apply lemmatization and store the output in a separate column\n",
        "df_clean[\"lemmatized_complaints\"] = df_clean[\"complaints_cleaned\"].swifter.apply(lemmatizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOiDVvEIJrF0"
      },
      "outputs": [],
      "source": [
        "df_clean.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKfY9weAjUUp"
      },
      "source": [
        "#### It is more likely the words of interest for Topic Modelling are nouns and proper nouns. Words with other POS tags are unlikely to be of much use to us. Hence, the code below creates a new column which includes only words with POS tags as nouns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk7fc4DuJrF1"
      },
      "outputs": [],
      "source": [
        "#Write your function to extract the POS tags (Using Spacy)\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "pos_tags = []  # List to store POS tags of each lemmatized complaint\n",
        "nouns = []     # List to store only the nouns from the complaint\n",
        "\n",
        "for complaint in tqdm(df_clean.lemmatized_complaints):\n",
        "    pos = ''\n",
        "    noun = ''\n",
        "    proc_complaint = nlp(complaint)\n",
        "    for tok in proc_complaint:\n",
        "        pos += tok.pos_ + ' '\n",
        "        if tok.pos_ in str(('NOUN', 'PROPN')) :\n",
        "            noun += (tok.lemma_.lower()) + ' '\n",
        "    pos_tags.append(pos.strip())\n",
        "    nouns.append(noun.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71T_qvvEjUUr"
      },
      "outputs": [],
      "source": [
        "df_clean['pos_tags_lemmatized'] = pd.Series(pos_tags, index=df_clean.index)\n",
        "df_clean['complaints_nouns_only'] = pd.Series(nouns, index=df_clean.index)\n",
        "\n",
        "#Reassigning index of cleaned dataframe\n",
        "df_clean.reset_index(drop=True, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjxfchvFJrF2"
      },
      "outputs": [],
      "source": [
        "#The clean dataframe should now contain the raw complaint, cleaned_complaints, lemmatized complaints with respective POS tags, \n",
        "#and the complaints after removing words with non-noun (NOUN, PROPN) POS tags.\n",
        "df_clean.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7Un1AElJrF2"
      },
      "source": [
        "## 3.Exploratory data analysis to get familiar with the data.\n",
        "\n",
        "Write the code in this task to perform the following:\n",
        "\n",
        "*   Visualise the data according to the 'Complaint' character length\n",
        "*   Using a word cloud find the top 40 words by frequency among all the articles after processing the text\n",
        "*   Find the top unigrams,bigrams and trigrams by frequency among all the complaints after processing the text. ‘\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jglj1oZrVwL4"
      },
      "outputs": [],
      "source": [
        "df_clean.complaint_what_happened.str.len().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-zaqJF6JrF2"
      },
      "outputs": [],
      "source": [
        "# Write your code here to visualise the data according to the 'Complaint' character length\n",
        "bins = [0, 100, 500, 1000, 5000, 10000, 50000]\n",
        "temp_df = df_clean.complaint_what_happened.str.len().to_frame()\n",
        "temp_df.columns = [\"length\"]\n",
        "temp_df['binned'] = pd.cut(temp_df['length'], bins)\n",
        "temp_df.binned.value_counts()\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "temp_df.binned.value_counts().plot(kind=\"bar\")\n",
        "plt.title(\"Complaint count by character length\")\n",
        "plt.xlabel(\"Character length ranges\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9jD_6SeJrF3"
      },
      "source": [
        "#### Find the top 40 words by frequency among all the articles after processing the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsioxWfZjUUt"
      },
      "outputs": [],
      "source": [
        "# Most frequent words in the processed (lemmatized) complaints\n",
        "most_freq_lem=[] # List to extract most frequent words\n",
        "\n",
        "for complaint in df_clean.lemmatized_complaints:\n",
        "    for word in complaint.split(' '):\n",
        "        most_freq_lem.append(word)\n",
        "\n",
        "plt.figure(figsize=(20, 5)) \n",
        "pd.DataFrame(most_freq_lem)[0].value_counts().head(40).plot(kind='bar')\n",
        "plt.title(\"Most frequent words in complaints after processing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAVCA3gTjUUu"
      },
      "outputs": [],
      "source": [
        "!pip install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcfdvtfZJrF3"
      },
      "outputs": [],
      "source": [
        "#Using a word cloud find the top 40 words by frequency among all the articles after processing the text\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "wordcloud = WordCloud(background_color = '#001a33', width = 1200, height = 600, colormap = 'viridis', max_words = 50, contour_width = 3, max_font_size = 100, contour_color = 'steelblue', random_state = 0)\n",
        "\n",
        "most_freq_words = pd.DataFrame(most_freq_lem)[0].value_counts().head(40).index\n",
        "wordcloud.generate(' '.join([w for w in most_freq_words]))\n",
        "\n",
        "plt.imshow(wordcloud)\n",
        "plt.title(\"Wordcloud of most frequent words in the processed complaints\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPdc4cQQjUUv"
      },
      "outputs": [],
      "source": [
        "# Most frequent nouns in the processed complaints\n",
        "most_freq_nouns=[] # List to extract most frequent nouns\n",
        "\n",
        "for complaint in df_clean.complaints_nouns_only:\n",
        "    for word in complaint.split(' '):\n",
        "        most_freq_nouns.append(word)\n",
        "\n",
        "plt.figure(figsize=(20, 5)) \n",
        "pd.DataFrame(most_freq_nouns)[0].value_counts().head(40).plot(kind='bar')\n",
        "plt.title(\"Most frequent nouns in the complaints\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7eH6ojYjUUv"
      },
      "outputs": [],
      "source": [
        "#Using a word cloud find the top 40 nouns by frequency among all the articles after processing the text\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "wordcloud = WordCloud(background_color = '#001a33', width = 1200, height = 600, colormap = 'viridis', max_words = 50, contour_width = 3, max_font_size = 100, contour_color = 'steelblue', random_state = 0)\n",
        "\n",
        "most_freq_noun_words = pd.DataFrame(most_freq_nouns)[0].value_counts().head(40).index\n",
        "wordcloud.generate(' '.join([w for w in most_freq_noun_words]))\n",
        "\n",
        "plt.imshow(wordcloud)\n",
        "plt.title(\"Wordcloud of most frequent nouns in the processed complaints\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DfCSbbmJrF4"
      },
      "source": [
        "#### Find the top unigrams,bigrams and trigrams by frequency among all the complaints after processing the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6Bl4LSKjUUy"
      },
      "outputs": [],
      "source": [
        "# Importing required libraries.\n",
        "from nltk.util import ngrams \n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mbk5DS5JrF4"
      },
      "outputs": [],
      "source": [
        "#Write your code here to find the top 30 unigram frequency among the complaints in the cleaned datafram(df_clean). \n",
        "vectorizer = CountVectorizer(ngram_range=(1,1), analyzer='word') \n",
        "word_vect = vectorizer.fit_transform(df_clean['complaints_nouns_only']) \n",
        "freqs = sum(word_vect).toarray()[0]\n",
        "\n",
        "unigram_df = pd.DataFrame(freqs, index=vectorizer.get_feature_names(), columns=['frequency']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrdnwXIyjUU0"
      },
      "outputs": [],
      "source": [
        "#Print the top 30 words in the unigram by frequency\n",
        "print(\"Top 30 words in the unigram by frequency:\")\n",
        "unigram_df.sort_values(by=\"frequency\", ascending = False).head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7vO0wQQjUU1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "unigram_df.sort_values(by='frequency', ascending=False)[:30].plot(kind='bar', figsize=(20,6), fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aV7kD7w8JrF8"
      },
      "outputs": [],
      "source": [
        "#Write your code here to find the top 30 bigram frequency among the complaints in the cleaned datafram(df_clean). \n",
        "vectorizer_bigram = CountVectorizer(ngram_range=(2, 2), analyzer='word') \n",
        "word_vector_bigram = vectorizer_bigram.fit_transform(df_clean['complaints_nouns_only']) \n",
        "freqs_bigram = sum(word_vector_bigram).toarray()[0]\n",
        "\n",
        "bigram_df = pd.DataFrame(freqs_bigram, index=vectorizer_bigram.get_feature_names(), columns=['frequency'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPnMNIpyJrF9"
      },
      "outputs": [],
      "source": [
        "#Print thelemmatized_complaints 10 words in the bigram frequency\n",
        "print(\"Top 30 bigrams by frequency:\")\n",
        "print(bigram_df.sort_values(by=\"frequency\", ascending = False).head(30))\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "bigram_df.sort_values(by='frequency', ascending=False)[:30].plot(kind='bar', figsize=(20,6), fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xkh7vtbtJrF-"
      },
      "outputs": [],
      "source": [
        "#Write your code here to find the top 30 trigram frequency among the complaints in the cleaned datafram(df_clean). \n",
        "vectorizer_trigram = CountVectorizer(ngram_range=(3,3), analyzer='word') \n",
        "word_vector_trigram = vectorizer_trigram.fit_transform(df_clean['complaints_nouns_only']) \n",
        "freqs_trigram = sum(word_vector_trigram).toarray()[0]\n",
        "\n",
        "trigram_df = pd.DataFrame(freqs_trigram, index=vectorizer_trigram.get_feature_names(), columns=['frequency'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REcVxNfvJrF-"
      },
      "outputs": [],
      "source": [
        "#Print the top 30 words in the trigram frequency\n",
        "print(\"Top 30 trigrams by frequency:\")\n",
        "print(trigram_df.sort_values(by=\"frequency\", ascending = False).head(30))\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "trigram_df.sort_values(by='frequency', ascending=False)[:30].plot(kind='bar', figsize=(20,6), fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUXzFji0JrF_"
      },
      "source": [
        "#### The personal details of customer has been masked in the dataset with xxxx. Let's remove the masked text as this will be of no use for our analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9fx7Mc1jUU6"
      },
      "outputs": [],
      "source": [
        "df_clean.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKda-a_IJrF_"
      },
      "outputs": [],
      "source": [
        "# Removing masked customer names and other masked data signified by 'xxxx', since they are of no use to us.\n",
        "df_clean['complaints_cleaned'] = df_clean['complaints_cleaned'].str.replace('xxxx','')\n",
        "df_clean['lemmatized_complaints'] = df_clean['lemmatized_complaints'].str.replace('xxxx','')\n",
        "df_clean['complaints_nouns_only'] = df_clean['complaints_nouns_only'].str.replace('xxxx','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UIFk8fQJrF_"
      },
      "outputs": [],
      "source": [
        "#All masked texts has been removed\n",
        "df_clean.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-I0k0QtJrGA"
      },
      "source": [
        "## 4.Feature Extraction\n",
        "Convert the raw texts to a matrix of TF-IDF features\n",
        "\n",
        "**max_df** is used for removing terms that appear too frequently, also known as \"corpus-specific stop words\"\n",
        "max_df = 0.95 means \"ignore terms that appear in more than 95% of the complaints\"\n",
        "\n",
        "**min_df** is used for removing terms that appear too infrequently\n",
        "min_df = 2 means \"ignore terms that appear in less than 2 complaints\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8fGwaCPJrGA"
      },
      "outputs": [],
      "source": [
        "#Write your code here to initialise the TfidfVectorizer \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    min_df=3,\n",
        "    max_df=0.9,\n",
        "    max_features=5000, # Keeping max_features to 5000 to keep within memory limits.\n",
        "    ngram_range=(1, 3)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYzD85nTJrGA"
      },
      "source": [
        "#### Create a document term matrix using fit_transform\n",
        "\n",
        "The contents of a document term matrix are tuples of (complaint_id,token_id) tf-idf score:\n",
        "The tuples that are not there have a tf-idf score of 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffzdDpp_JrGB"
      },
      "outputs": [],
      "source": [
        "#Write your code here to create the Document Term Matrix (tfidf) by transforming the complaints column present in df_clean.\n",
        "\n",
        "tfidf = tfidf_vectorizer.fit_transform(df_clean['complaints_nouns_only'])\n",
        "features = tfidf_vectorizer.get_feature_names()\n",
        "\n",
        "# Creating a dataframe to display the document-term matrix created above\n",
        "tfidf_df = pd.DataFrame(tfidf.toarray(), columns = features)\n",
        "tfidf_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH-3T4LTjUVA"
      },
      "outputs": [],
      "source": [
        "tfidf_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QBabqpYjUVA"
      },
      "outputs": [],
      "source": [
        "len(tfidf_vectorizer.get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q9lwvNEJrGB"
      },
      "source": [
        "## 5.Topic Modelling using NMF\n",
        "\n",
        "Non-Negative Matrix Factorization (NMF) is an unsupervised technique so there are no labeling of topics that the model will be trained on. The way it works is that, NMF decomposes (or factorizes) high-dimensional vectors into a lower-dimensional representation. These lower-dimensional vectors are non-negative which also means their coefficients are non-negative.\n",
        "\n",
        "In this task you have to perform the following:\n",
        "\n",
        "* Find the best number of clusters \n",
        "* Apply the best number to create word clusters\n",
        "* Inspect & validate the correction of each cluster wrt the complaints \n",
        "* Correct the labels if needed \n",
        "* Map the clusters to topics/cluster names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amLT4omWJrGB"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import NMF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wYR1xUTJrGD"
      },
      "source": [
        "## Manual Topic Modeling\n",
        "You need to do take the trial & error approach to find the best num of topics for your NMF model.\n",
        "\n",
        "The only parameter that is required is the number of components i.e. the number of topics we want. This is the most crucial step in the whole topic modeling process and will greatly affect how good your final topics are."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-gNAj03acwP"
      },
      "source": [
        "### Starting with 15 topics as a test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgd2A6bhJrGD"
      },
      "outputs": [],
      "source": [
        "#Load your nmf_model with the n_components \n",
        "\n",
        "#Initial test with num_topics = 15\n",
        "num_topics = 15 #write the value you want to test out\n",
        "\n",
        "#keep the random_state =40\n",
        "nmf_model = NMF(n_components=num_topics, random_state=40) #write your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPMDYbt_JrGE"
      },
      "outputs": [],
      "source": [
        "W = nmf_model.fit_transform(tfidf)  # Document-Topic matrix\n",
        "H = nmf_model.components_           # Topic-Term matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16kRfat5JrGE"
      },
      "outputs": [],
      "source": [
        "#Print the Top15 words for each of the topics\n",
        "words = np.array(tfidf_vectorizer.get_feature_names())\n",
        "topic_words = pd.DataFrame(np.zeros((num_topics, 15)), index=[f'Topic {i + 1}' for i in range(num_topics)],\n",
        "                           columns=[f'Word {i + 1}' for i in range(15)]).astype(str)\n",
        "for i in range(num_topics):\n",
        "    ix = H[i].argsort()[::-1][:15]\n",
        "    topic_words.iloc[i] = words[ix]\n",
        "\n",
        "topic_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcLLdiLva2jD"
      },
      "source": [
        "- There are perhaps too many topics and it is difficult to identify patterns / coherence within each topic.\n",
        "- It may be better to try smaller number of topics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv5ZnRqEbHNm"
      },
      "source": [
        "### Trying the same as above, but with 10 topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPyFeaj7jUVI"
      },
      "outputs": [],
      "source": [
        "#Load your nmf_model with the n_components \n",
        "\n",
        "# Trying 10 topics\n",
        "num_topics = 10 #write the value you want to test out\n",
        "\n",
        "#keep the random_state =40\n",
        "nmf_model = NMF(n_components=num_topics, random_state=40) #write your code here\n",
        "\n",
        "W = nmf_model.fit_transform(tfidf)  # Document-Topic matrix\n",
        "H = nmf_model.components_           # Topic-Term matrix\n",
        "\n",
        "words = np.array(tfidf_vectorizer.get_feature_names())\n",
        "topic_words = pd.DataFrame(np.zeros((num_topics, 15)), index=[f'Topic {i + 1}' for i in range(num_topics)],\n",
        "                           columns=[f'Word {i + 1}' for i in range(15)]).astype(str)\n",
        "for i in range(num_topics):\n",
        "    ix = H[i].argsort()[::-1][:15]\n",
        "    topic_words.iloc[i] = words[ix]\n",
        "\n",
        "topic_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfW7Lbx0bQT7"
      },
      "source": [
        "- There still isn't a lot of coherence within the topics.\n",
        "- Decreasing no. of topics further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg1Fxr4abuQ5"
      },
      "source": [
        "### Using 5 topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2JG2yQejUVI"
      },
      "outputs": [],
      "source": [
        "#Load your nmf_model with the n_components \n",
        "\n",
        "# Trying 5 topics\n",
        "num_topics = 5 #write the value you want to test out\n",
        "\n",
        "#keep the random_state =40\n",
        "nmf_model = NMF(n_components=num_topics, random_state=40) #write your code here\n",
        "\n",
        "W = nmf_model.fit_transform(tfidf)  # Document-Topic matrix\n",
        "H = nmf_model.components_           # Topic-Term matrix\n",
        "\n",
        "words = np.array(tfidf_vectorizer.get_feature_names())\n",
        "topic_words = pd.DataFrame(np.zeros((num_topics, 15)), index=[f'Topic {i + 1}' for i in range(num_topics)],\n",
        "                           columns=[f'Word {i + 1}' for i in range(15)]).astype(str)\n",
        "for i in range(num_topics):\n",
        "    ix = H[i].argsort()[::-1][:15]\n",
        "    topic_words.iloc[i] = words[ix]\n",
        "\n",
        "topic_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW1kiNx0bzUq"
      },
      "source": [
        "- This seems to capture coherence within topics.\n",
        "- Let's proceed with 5 topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OIT7LmFJrGF"
      },
      "outputs": [],
      "source": [
        "#Create the best topic for each complaint in terms of integer value 0,1,2,3 & 4\n",
        "topic_mapping_num = {\n",
        "    'Topic 1' : 0,\n",
        "    'Topic 2' : 1,\n",
        "    'Topic 3' : 2,\n",
        "    'Topic 4' : 3,\n",
        "    'Topic 5' : 4\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jdqMapEjUVK"
      },
      "outputs": [],
      "source": [
        "W = pd.DataFrame(W, columns=[f'Topic {i+1}' for i in range(num_topics)])\n",
        "W['max_topic'] = W.apply(lambda x: topic_mapping_num.get(x.idxmax()) if x.idxmax() in topic_mapping_num.keys() else '4', axis=1)\n",
        "W[pd.notnull(W['max_topic'])].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oasj0uDdjUVK"
      },
      "outputs": [],
      "source": [
        "# Checking the frequency of each identified topic\n",
        "W['max_topic'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peyYv-ORJrGF"
      },
      "outputs": [],
      "source": [
        "#Assign the best topic to each of the cmplaints in Topic Column\n",
        "df_clean['Topic'] =W['max_topic'].apply(lambda x:int(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLh_Gf3nJrGF"
      },
      "outputs": [],
      "source": [
        "df_clean.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCrH7ZHVjUVM"
      },
      "outputs": [],
      "source": [
        "df_clean.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQKpufSPJrGG"
      },
      "outputs": [],
      "source": [
        "#Print the first 5 Complaint for each of the Topics\n",
        "df_clean_sample = df_clean.groupby('Topic').head(5)\n",
        "\n",
        "#df_clean_sample.sort_values('Topic')\n",
        "df_clean_sample.sort_values(by='Topic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAw9WoaFjUVN"
      },
      "outputs": [],
      "source": [
        "# Checking whether each complaint has an assigned topic or not; and whether the count for each topic matches that from our Document-Topic matrix\n",
        "df_clean.Topic.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piyLxzj6v07j"
      },
      "source": [
        "#### After evaluating the mapping, if the topics assigned are correct then assign these names to the relevant topic:\n",
        "* Bank Account services\n",
        "* Credit card or prepaid card\n",
        "* Mortgage/Loan\n",
        "* Theft/Dispute Reporting\n",
        "* Others"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWpwDG4RJrGG"
      },
      "outputs": [],
      "source": [
        "#Create the dictionary of Topic names and Topics\n",
        "\n",
        "Topic_names =   {\n",
        "                0 : \"Bank account services\",\n",
        "                1 : \"Credit Card/Prepaid Card\",\n",
        "                2 : \"Mortgages/loans\",\n",
        "                3 : \"Theft/Dispute reporting\",\n",
        "                4 : \"Others\"\n",
        "                }\n",
        "#Replace Topics with Topic Names\n",
        "df_clean['Topic'] = df_clean['Topic'].map(Topic_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2ULY5K6JrGG"
      },
      "outputs": [],
      "source": [
        "df_clean.Topic.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Mu0QBOcJrGH"
      },
      "source": [
        "## 6.Supervised model to predict any new complaints to the relevant Topics.\n",
        "\n",
        "You have now build the model to create the topics for each complaints.Now in the below section you will use them to classify any new complaints.\n",
        "\n",
        "Since you will be using supervised learning technique we have to convert the topic names to numbers(numpy arrays only understand numbers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_U8J3J8wJrGH"
      },
      "outputs": [],
      "source": [
        "#Create the dictionary again of Topic names and Topics\n",
        "\n",
        "topic_labels = {\n",
        "    \"Bank account services\" : 0,\n",
        "    \"Credit Card/Prepaid Card\" : 1,\n",
        "    \"Mortgages/loans\" : 2,\n",
        "    \"Theft/Dispute reporting\" : 3,\n",
        "    \"Others\" : 4\n",
        "}\n",
        "#Replace Topics with Topic labels\n",
        "df_clean['Topic'] = df_clean['Topic'].map(topic_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWIgJUkQJrGH"
      },
      "outputs": [],
      "source": [
        "df_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx-FrbkWJrGH"
      },
      "outputs": [],
      "source": [
        "#Keep the columns\"complaint_what_happened\" & \"Topic\" only in the new dataframe --> training_data\n",
        "training_data=df_clean[[\"complaint_what_happened\",\"Topic\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn7VRltDjUVU"
      },
      "outputs": [],
      "source": [
        "training_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVg2pa12JrGI"
      },
      "outputs": [],
      "source": [
        "training_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVN_wXeFjUVZ"
      },
      "outputs": [],
      "source": [
        "training_data.Topic.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "280Vbqk-7a8M"
      },
      "source": [
        "#### Apply the supervised models on the training data created. In this process, you have to do the following:\n",
        "* Create the vector counts using Count Vectoriser\n",
        "* Transform the word vecotr to tf-idf\n",
        "* Create the train & test data using the train_test_split on the tf-idf & topics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUlQpgkzJrGI"
      },
      "outputs": [],
      "source": [
        "#Write your code to get the Vector count\n",
        "vectorizer = CountVectorizer(ngram_range=(1,3), stop_words='english', max_df=0.95, min_df=0.02)\n",
        "vector = vectorizer.fit_transform(training_data.complaint_what_happened)\n",
        "\n",
        "print(vector.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHKQcDWrjUVd"
      },
      "outputs": [],
      "source": [
        "#Write your code here to transform the word vector to tf-idf\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer =TfidfTransformer(use_idf=True).fit(vector)\n",
        "word_vect = tfidf_transformer.transform(vector)\n",
        "word_vect.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMU3vj6w-wqL"
      },
      "source": [
        "You have to try atleast 3 models on the train & test data from these options:\n",
        "* Logistic regression\n",
        "* Decision Tree\n",
        "* Random Forest\n",
        "* Naive Bayes (optional)\n",
        "\n",
        "**Using the required evaluation metrics judge the tried models and select the ones performing the best**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udLHpPsZJrGI"
      },
      "source": [
        "## Write your code here to build any 3 models and evaluate them using the required metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmcf8HpUc-qN"
      },
      "source": [
        "## 7.Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-an-RVeOjUVg"
      },
      "source": [
        "### Preparing the data for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMUJdTkejUVg"
      },
      "outputs": [],
      "source": [
        "# Creating a dataframe of the tf-idf vector for use in model training.\n",
        "word_vect_df = pd.DataFrame(word_vect.toarray(),columns=vectorizer.get_feature_names(),index=training_data.index)\n",
        "word_vect_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fut1aVzujUVj"
      },
      "outputs": [],
      "source": [
        "word_vect_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TolrSNkfdU7Y"
      },
      "source": [
        "- Hence, there are 883 features that are being used for our training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ3njUz0jUVn"
      },
      "outputs": [],
      "source": [
        "# Displaying feature names\n",
        "features = vectorizer.get_feature_names()\n",
        "print(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbU7-RF7jUVq"
      },
      "outputs": [],
      "source": [
        "# Assigning our target variable to the word vector dataframe\n",
        "word_vect_df[\"Topic\"] = training_data[\"Topic\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHA6_8cJjUVr"
      },
      "source": [
        "### Train-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlsh7GYkjUVs"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X= word_vect_df.drop(['Topic'], axis=1)\n",
        "y= word_vect_df['Topic']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiQOl1atjUVs"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=0.25, random_state=40, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUh1ziIcjUVt"
      },
      "source": [
        "#### Choosing \"accuracy\" as our metric of evaluation, since this is a multi-class problem, Other metrics like precision, recall, etc. are more appropriate for "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS9Dp8l9jUVt"
      },
      "outputs": [],
      "source": [
        "# Defining a function to evaluate the models\n",
        "from sklearn import metrics\n",
        "\n",
        "def evaluate_model(y_actual,y_pred):\n",
        "       \n",
        "    # Confusion matrix\n",
        "    confusion = metrics.confusion_matrix(y_actual, y_pred)\n",
        "\n",
        "    # Metrics calculation\n",
        "    accuracy = metrics.accuracy_score(y_actual,y_pred)\n",
        "    clf_report = metrics.classification_report(y_actual,y_pred)   # Sklearn classification report\n",
        "    \n",
        "    print(\"Accuracy   : \" + str(accuracy))\n",
        "    print(\"\\nConfusion matrix:\\n\", confusion)\n",
        "    print(\"\\nClassificationReport:\")\n",
        "    print(clf_report)\n",
        "    \n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rI6NpETjUVu"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2OznsObJrGP"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred=logreg.predict(X_train)\n",
        "y_pred = logreg.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkxEk9mcjUVu"
      },
      "outputs": [],
      "source": [
        "lr_train_accuracy = evaluate_model(y_train.values,y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja_q434hjUVv"
      },
      "outputs": [],
      "source": [
        "lr_test_acc = evaluate_model(y_test.values,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TZsxlpWjUVv"
      },
      "source": [
        "### Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbywppbvjUVw"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Checking initial tree with standard params\n",
        "tree = DecisionTreeClassifier(random_state=40, max_depth=10, min_samples_leaf = 10, class_weight=\"balanced\")\n",
        "tree.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl7bo702jUVx"
      },
      "outputs": [],
      "source": [
        "y_train_pred_tree = tree.predict(X_train)\n",
        "y_test_pred_tree = tree.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTLxnnXNjUVx"
      },
      "outputs": [],
      "source": [
        "tree_train_acc = evaluate_model(y_train.values,y_train_pred_tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "883Nq7aMjUVy"
      },
      "outputs": [],
      "source": [
        "tree_test_acc = evaluate_model(y_test.values,y_test_pred_tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTm0FpHljUVy"
      },
      "source": [
        "#### Hyperparameter Tuning for Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4dTlh-ajUVz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "\n",
        "folds = StratifiedKFold(n_splits=5, shuffle = True, random_state=40)\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=40, class_weight=\"balanced\")\n",
        "params_dt = {\n",
        "    'max_depth': [5, 10, 20, 40],\n",
        "    'min_samples_leaf': [5, 10, 20, 50]\n",
        "}\n",
        "\n",
        "dt_cv = GridSearchCV(estimator = dt, param_grid = params_dt, scoring = \"accuracy\",\n",
        "                           cv=folds, n_jobs=-1, verbose=1, return_train_score=True)\n",
        "\n",
        "dt_cv.fit(X_train, y_train)\n",
        "\n",
        "dt_cv_results = pd.DataFrame(dt_cv.cv_results_)\n",
        "print(dt_cv.best_params_)\n",
        "dt_cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOsZoILgjUV1"
      },
      "outputs": [],
      "source": [
        "dt_best = DecisionTreeClassifier(random_state=40, max_depth = 20, min_samples_leaf = 10, class_weight=\"balanced\")\n",
        "dt_best.fit(X_train,y_train)\n",
        "\n",
        "y_train_pred_dt = dt_best.predict(X_train)\n",
        "y_test_pred_dt = dt_best.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRNcW6GWsudm"
      },
      "outputs": [],
      "source": [
        "dt_train_acc = evaluate_model(y_train.values,y_train_pred_dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taweIxqPsxtS"
      },
      "outputs": [],
      "source": [
        "dt_test_acc = evaluate_model(y_test.values,y_test_pred_dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-6WbJp_s_BV"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xagT4G5ms3U0"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight=\"balanced\")\n",
        "\n",
        "folds = StratifiedKFold(n_splits=5, shuffle = True, random_state=40)\n",
        "\n",
        "params_rf = {\n",
        "            'max_depth': [2, 5, 10],\n",
        "            'min_samples_leaf': [50, 100, 200],\n",
        "            'max_features': [8, 10],\n",
        "            'n_estimators': [50, 100, 200]\n",
        "            }\n",
        "\n",
        "rf_cv = GridSearchCV(estimator = rf, param_grid = params_rf, scoring = \"accuracy\",\n",
        "                           cv=folds, n_jobs=-1, verbose=1, return_train_score=True)\n",
        "\n",
        "rf_cv.fit(X_train,y_train)\n",
        "\n",
        "rf_cv_results = pd.DataFrame(rf_cv.cv_results_)\n",
        "print(rf_cv.best_params_)\n",
        "rf_cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fIOGgUStFVf"
      },
      "outputs": [],
      "source": [
        "rf_best = rf_cv.best_estimator_\n",
        "rf_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nqobbyfvp9t"
      },
      "outputs": [],
      "source": [
        "rf_best.fit(X_train,y_train)\n",
        "\n",
        "y_train_pred_rf = rf_best.predict(X_train)\n",
        "y_test_pred_rf = rf_best.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSUXSCMOv6Xp"
      },
      "outputs": [],
      "source": [
        "rf_train_acc = evaluate_model(y_train.values,y_train_pred_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXsKtTByv_ZA"
      },
      "outputs": [],
      "source": [
        "rf_test_acc = evaluate_model(y_test.values,y_test_pred_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br0Jxl14e2va"
      },
      "source": [
        "### Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGVXfM-Fx2En"
      },
      "outputs": [],
      "source": [
        "# Creating a dataframe to summarise the results of each model.\n",
        "summary_df = pd.DataFrame({\"Training Accuracy\":[lr_train_accuracy,dt_train_acc,rf_train_acc], \"Test Accuracy\":[lr_test_acc,dt_test_acc,rf_test_acc]}, \n",
        "                      index = ['Logistic Regression','Decision Tree Classifier',\"Random Forest Classifier\"])\n",
        "\n",
        "summary_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-5N0w_tzdLU"
      },
      "source": [
        "- We can infer that a standard logistic regression model is able to perform the best for our use case. There is also no major overfitting that we should be concerned about.\n",
        "- We can test the results using custom texts next to check the performance of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43cSmmifx0v4"
      },
      "source": [
        "## 8.Model Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5qsprQpE9CX"
      },
      "source": [
        "### Evaluation of model performance with unseen sample text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMw2YGJof15D"
      },
      "outputs": [],
      "source": [
        "print(Topic_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRBFQ0ZKzVgF"
      },
      "outputs": [],
      "source": [
        "# Function to first vectorize the custom text for use with our model. The function then predicts the appropriate topic for the text.\n",
        "def predict_complaint(sentence, model=logreg):\n",
        "    \n",
        "    # Vectorizing the text to apply the model. Using the same vectorizer which was fit on the training data to maintain parity.\n",
        "    vect_custom = vectorizer.transform(pd.Series(sentence))\n",
        "    word_vect_custom = tfidf_transformer.transform(vect_custom)\n",
        "\n",
        "    # Converting to a dataframe\n",
        "    word_vect_custom_df = pd.DataFrame(word_vect_custom.toarray(),columns=vectorizer.get_feature_names())\n",
        "\n",
        "    # Making predictions\n",
        "    custom_pred = model.predict(word_vect_custom_df)\n",
        "    \n",
        "    # Printing predicted output. Using the Topic_names dictionary mapping defined earlier in the notebook.\n",
        "    print(\"The text can be classified under topic number {0}, which belongs to the following category: {1}\".format(custom_pred[0],Topic_names[custom_pred[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUKtB8UEDu9R"
      },
      "outputs": [],
      "source": [
        "# Custom text 1\n",
        "text1 = \"This letter is to dispute an incorrectly charged amount on my credit card. My credit card number is XCXCXXC and it has a constant record of all bills cleared at the appropriate time. I want to inform you that the statement issued to me from bank includes an erroneous charge of Rs. 10,000, dated 20th February 2014. I have enclosed a copy of the statement with the false charge circled in red. This particular payment was cancelled on the same day since I had returned the purchase soon after. It was billed from -Creditor’s name. I have attached a copy of the cancelled bill along with the authorized signature of the creditor. I was quite surprised to find this amount included in my bills because never before has such an error happened in the billings of my credit card.\"\n",
        "predict_complaint(text1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNqIJikJFRUi"
      },
      "outputs": [],
      "source": [
        "# Custom text 2\n",
        "text2 = \"The purpose of this letter is to request a small business loan in the amount of $20,000 for the purpose of enlarging our warehouse. Entirely Electronics began operation on June 1, 2020, with two employees. As a partnership, Entirely, Electronics has consistently grown and now has 20 full-time employees. Entirely Electronics has been quite successful in obtaining a proportionate share of the online electronic retail community. Our online presence has grown from our website alone to Facebook, Instagram, and Yelp. Our marketing techniques consistently drive new customers to Entirely Electronics, and we boast a high customer retention rate.\"\n",
        "predict_complaint(text2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfGlvdwqFp8_"
      },
      "outputs": [],
      "source": [
        "# Custom text 3\n",
        "text3 = \"I would like to convert my account from a savings to a current account with zero balance facility. Please guide me on the process to do so.\"\n",
        "predict_complaint(text3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruLr9EmbHPO4"
      },
      "outputs": [],
      "source": [
        "# Custom text 4\n",
        "text4 = \"i want to report an incident of incorrect debit of funds. Please look into possible phishing attacks\"\n",
        "predict_complaint(text4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teCI7AZAhBIU"
      },
      "source": [
        "### Conclusions\n",
        "- This concludes this exercise of trying to automatically classify tickets(complaints) in the banking sector.\n",
        "- A reasonably good model has been obtained which is able to predict the appropriate category of the ticket as required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jGvpP70hnCL"
      },
      "source": [
        "## End of Project"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "T9jD_6SeJrF3",
        "5DfCSbbmJrF4",
        "yYzD85nTJrGA",
        "piyLxzj6v07j",
        "280Vbqk-7a8M"
      ],
      "name": "Automatic_Ticket_Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}